A cryptocurrency trading platform is using an API built in AWS Lambda and API Gateway. Due to the recent news and rumors about the upcoming price surge of Bitcoin, Ethereum and other cryptocurrencies, it is expected that the trading platform would have a significant increase in site visitors and new users in the coming days ahead.

In this scenario, how can you protect the backend systems of the platform from traffic spikes?

(A) Switch from using AWS Lambda and API Gateway to a more scalable and highly available architecture using EC2 instances, ELB, and Auto Scaling.
(B) Enable throttling limits and result caching in API Gateway.
(C) Use CloudFront in front of the API Gateway to act as a cache.
(D) Move the Lambda function in a VPC.

Answer: 
(B) Enable throttling limits and result caching in API Gateway.
API Gateway is a highly scalable and highly available architecture, which makes it suitable for protecting backend systems from traffic spikes. By enabling throttling limits in API Gateway, you can control the number of requests that can be made to the backend system within a certain time period, thus preventing overloading.
Additionally, result caching in API Gateway can help reduce the load on the backend system by caching the results of previous requests, thereby reducing the number of requests made to the backend system. This can help protect the backend systems from traffic spikes and ensure that they can handle a large number of requests without overloading.
Option (A) is not a suitable solution as it would require significant changes to the platform's architecture and infrastructure, which may not be practical or feasible in this scenario. Option (C) is also not a suitable solution as CloudFront is primarily designed for caching static content, and may not provide the necessary protection against traffic spikes on the backend systems. Option (D) is also not a suitable solution as it would require significant changes to the platform's infrastructure and architecture, which may not be practical or feasible in this scenario.